<?xml version="1.0"?>
<!--    Records raw depth image and RGB image from OpenNI device (kinect).
The depth image is registered with OpenNI firmware, using default calibration.-->

<launch>
	<!--  First we start the openni driver, and all the related
	post-processing to get point clouds: actually we don't need all that but in case you want to visualise it in action this is done. For an alternative that does not do that see http://mirror.umd.edu/roswiki/openni_launch(2f)Tutorials(2f)BagRecordingPlayback.html - just change the following line for the appropriate openni_camera node with depth registration switched on, and the rgb and depth frame ids set -->
	<include file="$(find openni_launch)/launch/openni.launch">
		<arg name="load_driver" value="true" />
		<arg name="depth_registration" value="true"/>
		<arg name="camera" value="kinect"/>
	</include>

  <param name="/head_mount_kinect/driver/data_skip" value="1" />

  <node pkg="image_view" type="image_view" name="image_view_node" output="screen" args="image:=/kinect/rgb/image_raw"/>


</launch>
